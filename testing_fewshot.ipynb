{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from libs.docx_parser import getDoc\n",
    "from libs.docx_parser import getCsv\n",
    "from langchain import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargo variables de configuración\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este código se ejecuta cada vez que desea generar el csv de los Excel de los CP.\n",
    "#from libs.convert_excel_to_csv import convert_xlsx_to_csv\n",
    "\n",
    "#convert_xlsx_to_csv('documentos/redenciones/cp_redenciones.xlsx', 'Casos de Prueba', 'documentos/redenciones/cp_redenciones.csv', 5, 8, 'Unnamed: 2', 'Unnamed: 7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga documento input y tabla objetivo.\n",
    "#context_file1 = 'documentos/migraciones/cp_migraciones.docx'\n",
    "#context1 = getDoc(context_file1)\n",
    "\n",
    "#targte_file1 = 'documentos/migraciones/objetivos_migraciones.csv'\n",
    "#target1 = getCsv(targte_file1)\n",
    "\n",
    "# Carga documento input y tabla objetivo.\n",
    "context_file2 = 'documentos/redenciones/cp_redenciones.docx'\n",
    "context2 = getDoc(context_file2)\n",
    "\n",
    "targte_file2 = 'documentos/redenciones/cp_redenciones.csv'\n",
    "target2 = getCsv(targte_file2)\n",
    "\n",
    "# Carga documento input y tabla objetivo.\n",
    "#context_file3 = 'documentos/msi/cp_msi.docx'\n",
    "#context3 = getDoc(context_file3)\n",
    "\n",
    "#targte_file3 = 'documentos/msi/objetivos_msi.csv'\n",
    "#target3 = getCsv(targte_file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You will be provided with a context from which you should extract multiple test cases by identifying the following aspects:\n",
    " 'Caso de prueba', 'Modulo', 'Funcionalidad', 'Proceso' and 'Segmento'.\n",
    "   As the text contains multiple test cases, the output should be presented in a csv format table.\n",
    "   Here is an example:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"context\": context2,\n",
    "        \"result\": target2\n",
    "    } \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'examples = [\\n    {\\n        \"context\": context1,\\n        \"result\": target1\\n    },\\n    {\\n        \"context\": context2,\\n        \"result\": target2\\n    },\\n    {\\n        \"context\": context3,\\n        \"result\": target3\\n    }\\n]'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"examples = [\n",
    "    {\n",
    "        \"context\": context1,\n",
    "        \"result\": target1\n",
    "    },\n",
    "    {\n",
    "        \"context\": context2,\n",
    "        \"result\": target2\n",
    "    },\n",
    "    {\n",
    "        \"context\": context3,\n",
    "        \"result\": target3\n",
    "    }\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template = \"\"\"\n",
    "Context: {context}\n",
    "Result: {result}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"result\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "\n",
    "prefix = \"\"\"Sos parte del equipo de testing re una compania de telecomunicaciones.\n",
    "Te voy a dar un documento con requerimientos de testeo para uno de los modulos de la aplicacion.\n",
    "Necesito que hagas una lista con todos los casos de prueba que puedas identificar.\n",
    " Deberás incluir la condicion esperada para cada uno de los casos.\n",
    "    \n",
    "   Aqui hay ejemplos:\n",
    "   \"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "Context: {new_context}\n",
    "Result: \"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"new_context\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contexto_path = 'documentos/migraciones/hu_migraciones.docx'\n",
    "contexto_path = 'documentos/redenciones/hu_redenciones.docx'\n",
    "#contexto_path = 'documentos/msi/hu_msi.docx'\n",
    "nuevo_contexto = getDoc(contexto_path)\n",
    "#print(nuevo_contexto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI (\n",
    "        azure_endpoint=os.getenv('API_BASE'),\n",
    "        openai_api_version=os.getenv('API_VERSION'),\n",
    "        deployment_name=os.getenv('CHAT_ENGINE_16K'),\n",
    "        openai_api_key=os.getenv('API_KEY'),\n",
    "        openai_api_type=os.getenv('API_TYPE'),\n",
    "        temperature=0,\n",
    "        model_version=\"0613\" # es importante aclararlo para el correcto calculo de los costos\n",
    "        )\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=few_shot_prompt_template)\n",
    "\n",
    "result = llm_chain(nuevo_contexto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Prueba de ingreso al mantenedor con el usuario NBA en la sección Parrillas flujos nativos, Pestaña Fidelización y Crear bloque.\\n   - Condición esperada: Creación exitosa del bloque.\\n\\n2. Prueba de ingreso al mantenedor con el usuario NBA en la sección reportes y redención.\\n   - Condición esperada: Generación exitosa del reporte.\\n\\n3. Prueba de ingreso a la aplicación con un DN apto para redención y selección de beneficio.\\n   - Condición esperada: Flujo de redención exitoso y pantalla de Success.\\n\\n4. Prueba de ingreso a la aplicación con el DN 5537685200 y selección de beneficio.\\n   - Condición esperada: Flujo de redención exitoso y pantalla de Success.\\n\\n5. Prueba de ingreso al mantenedor en la sección Parrillas y creación de bono, regalo o descuento.\\n   - Condición esperada: Creación exitosa del bono, regalo o descuento.\\n\\n6. Prueba de ingreso al mantenedor en la sección Parrillas y configuración de la campaña de fidelización.\\n   - Condición esperada: Configuración exitosa de la campaña de fidelización.\\n\\n7. Prueba de generación de reporte por rango de fechas en el mantenedor.\\n   - Condición esperada: Descarga exitosa del reporte con los clientes que hayan seleccionado algún bono, descuento y/o regalo.\\n\\n8. Prueba de generación de Deeplink para comunicación de los beneficios.\\n   - Condición esperada: Generación exitosa del Deeplink.\\n\\n9. Prueba de visualización de los bonos, descuentos y/o regalos en la sección de fidelización de la APP.\\n   - Condición esperada: Visualización correcta de los bonos, descuentos y/o regalos disponibles.\\n\\n10. Prueba de selección de bono, descuento y/o regalo por parte del cliente.\\n    - Condición esperada: Desaparición de la opción de fidelización en la APP y registro de la selección realizada.\\n\\n11. Prueba de configuración de fecha de inicio y fecha fin para bonos, descuentos y/o regalos en el mantenedor.\\n    - Condición esperada: Configuración correcta de las fechas de inicio y fin.\\n\\n12. Prueba de subida de imagen en el mantenedor para mostrar al cliente con bono, descuento y/o regalo.\\n    - Condición esperada: Subida exitosa de la imagen.\\n\\n13. Prueba de validación de antigüedad del cliente en el Query cost para impactar los beneficios configurados.\\n    - Condición esperada: Validación correcta de la antigüedad del cliente y aplicación de los beneficios correspondientes.\\n\\n14. Prueba de selección de bono, descuento y/o regalo por parte del cliente y registro en el reporte.\\n    - Condición esperada: Registro correcto del DN del cliente, bono seleccionado y fecha en el reporte.\\n\\n15. Prueba de aplicación de descuento único para cada cliente.\\n    - Condición esperada: Búsqueda de la mejor manera de aplicar los descuentos y aplicación exitosa de los mismos.\\n\\n16. Prueba de aplicación de regalos a través de un intermediario.\\n    - Condición esperada: Envío exitoso del descuento o regalo al cliente a través del intermediario.\\n\\n17. Prueba de carga de nueva base para volver a visualizar las opciones de bonos, descuentos y/o regalos.\\n    - Condición esperada: Visualización nuevamente de las opciones de bonos, descuentos y/o regalos después de cargar la nueva base.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardo el resultado de result['text] en un archvivo .csv\n",
    "with open('documentos/resultados/redenciones_fs.csv', 'w') as f:\n",
    "    f.write(result['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
